# Python Executor Service - å‡çº§å»ºè®® v2.0

## ğŸ“Š å½“å‰çŠ¶æ€è¯„ä¼°ï¼ˆv1.2.0+ï¼‰

### âœ… å·²å®Œæˆçš„åŠŸèƒ½

#### 1. æ ¸å¿ƒåŠŸèƒ½
- âœ… **å®‰å…¨æ²™ç®±**ï¼šRestrictedPython + ç™½åå•æœºåˆ¶
- âœ… **æ™ºèƒ½ç¼©è¿›**ï¼šä½¿ç”¨æ ˆç®—æ³•å¤„ç†ä»£ç å—å±‚çº§
- âœ… **æ•°æ®é›†ä¼ é€’**ï¼šdatasets + selected_files åŒæ ¼å¼æ”¯æŒ
- âœ… **é¢„åŠ è½½å˜é‡**ï¼špreloadedVariables æ”¯æŒ
- âœ… **è‡ªåŠ¨å‡½æ•°è¦†ç›–**ï¼špd.read_csv/read_json å†…å­˜è¯»å–

#### 2. åº“æ”¯æŒï¼ˆæœ€æ–°æ›´æ–° âœ¨ï¼‰
- âœ… **æ•°æ®å¤„ç†**ï¼šNumPy, Pandas, SciPy
- âœ… **æœºå™¨å­¦ä¹ **ï¼šScikit-learn (å®Œæ•´)
- âœ… **å¯è§†åŒ–**ï¼šMatplotlib, Plotly, Seaborn
- âœ… **å›¾åƒå¤„ç†**ï¼šPIL/Pillow (Image, ImageEnhance, ImageFilter) ğŸ†•
- âœ… **æ ‡å‡†åº“**ï¼šio, base64, json, re, collections.Counter ğŸ†•

#### 3. ç¼©è¿›å¤„ç†ï¼ˆæœ€æ–°ç®—æ³• âœ¨ï¼‰
- âœ… ä½¿ç”¨ç¼©è¿›æ ˆè¿½è¸ªä»£ç å—å±‚çº§
- âœ… æ™ºèƒ½è¯†åˆ«é¡¶å±‚è¯­å¥ï¼ˆimport, def, classï¼‰
- âœ… è‡ªåŠ¨ä¿®å¤ä¸ä¸€è‡´ç¼©è¿›
- âœ… æ­£ç¡®å¤„ç†ä»£ç å—ç»“æ„ï¼ˆå†’å·ç»“å°¾ï¼‰

---

## ğŸ¯ å‡çº§æ–¹å‘å»ºè®®

### ğŸ“ˆ ä¼˜å…ˆçº§åˆ†ç±»

```
P0 = ç«‹å³å®æ–½ï¼ˆ1-2å‘¨ï¼‰
P1 = è¿‘æœŸè§„åˆ’ï¼ˆ1-2ä¸ªæœˆï¼‰
P2 = ä¸­æœŸè§„åˆ’ï¼ˆ3-6ä¸ªæœˆï¼‰
P3 = é•¿æœŸè§„åˆ’ï¼ˆ6ä¸ªæœˆ+ï¼‰
```

---

## ğŸš€ ä¸€ã€å›¾ç‰‡å¤„ç†å¢å¼ºï¼ˆP0 - ç«‹å³å¯åšï¼‰

### ç°çŠ¶
- âœ… PIL/Pillow å·²å¯¼å…¥
- âœ… Image, ImageEnhance, ImageFilter å·²æ”¯æŒ
- âœ… io, base64 å·²æ”¯æŒ
- âš ï¸ ç¼ºå°‘ä½¿ç”¨æ–‡æ¡£å’Œç¤ºä¾‹

### å»ºè®®ï¼šå®Œå–„å›¾ç‰‡å¤„ç†åŠŸèƒ½

#### 1.1 åˆ›å»ºå›¾ç‰‡å¤„ç†æ¨¡æ¿

**æ–°å¢ä»£ç æ¨¡æ¿**ï¼š

```python
# æ¨¡æ¿ 1: image_format_convert
"""æ‰¹é‡å›¾ç‰‡æ ¼å¼è½¬æ¢"""
from PIL import Image
import io
import base64

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
        # è§£ç å›¾ç‰‡
        img_data = base64.b64decode(file['content'])
        img = Image.open(io.BytesIO(img_data))

        # è½¬æ¢ä¸º PNG
        output = io.BytesIO()
        if img.mode == 'RGBA':
            img.save(output, format='PNG')
        else:
            img = img.convert('RGB')
            img.save(output, format='PNG')

        result = base64.b64encode(output.getvalue()).decode()
        print(f"âœ“ {file['name']} -> PNG")

# æ¨¡æ¿ 2: image_compress
"""æ‰¹é‡å›¾ç‰‡å‹ç¼©"""
from PIL import Image
import io
import base64

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png')):
        img_data = base64.b64decode(file['content'])
        img = Image.open(io.BytesIO(img_data))

        # è°ƒæ•´å°ºå¯¸
        img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)

        # å‹ç¼©
        output = io.BytesIO()
        if img.mode == 'RGBA':
            img = img.convert('RGB')
        img.save(output, format='JPEG', quality=85, optimize=True)

        original_size = len(img_data)
        new_size = output.tell()
        saved = (1 - new_size/original_size) * 100

        print(f"âœ“ {file['name']}: {original_size/1024:.1f}KB â†’ {new_size/1024:.1f}KB (çœ{saved:.1f}%)")

# æ¨¡æ¿ 3: image_analysis
"""å›¾ç‰‡æ•°æ®é›†åˆ†æ"""
from PIL import Image
import io
import base64

image_stats = {
    'count': 0,
    'formats': {},
    'total_size': 0,
    'avg_width': 0,
    'avg_height': 0
}

widths = []
heights = []

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):
        img_data = base64.b64decode(file['content'])
        img = Image.open(io.BytesIO(img_data))

        image_stats['count'] += 1
        image_stats['formats'][img.format] = image_stats['formats'].get(img.format, 0) + 1
        image_stats['total_size'] += len(img_data)

        widths.append(img.width)
        heights.append(img.height)

if widths:
    image_stats['avg_width'] = sum(widths) / len(widths)
    image_stats['avg_height'] = sum(heights) / len(heights)

print("=" * 60)
print("å›¾ç‰‡æ•°æ®é›†åˆ†ææŠ¥å‘Š")
print("=" * 60)
print(f"æ€»å›¾ç‰‡æ•°: {image_stats['count']}")
print(f"æ ¼å¼åˆ†å¸ƒ: {image_stats['formats']}")
print(f"å¹³å‡å°ºå¯¸: {image_stats['avg_width']:.0f} x {image_stats['avg_height']:.0f}")
print(f"æ€»å¤§å°: {image_stats['total_size']/1024/1024:.2f} MB")

# æ¨¡æ¿ 4: image_enhance
"""å›¾ç‰‡å¢å¼ºå¤„ç†"""
from PIL import Image, ImageEnhance
import io
import base64

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png')):
        img_data = base64.b64decode(file['content'])
        img = Image.open(io.BytesIO(img_data))

        # å¢å¼ºäº®åº¦
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(1.2)

        # å¢å¼ºå¯¹æ¯”åº¦
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.1)

        # é”åŒ–
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.5)

        print(f"âœ“ {file['name']} å·²å¢å¼º")
```

**å®æ–½æ­¥éª¤**ï¼š
1. åœ¨ `app/sandbox.py` çš„ `CODE_TEMPLATES` æ·»åŠ è¿™4ä¸ªæ¨¡æ¿
2. æµ‹è¯•æ¯ä¸ªæ¨¡æ¿
3. æ›´æ–° API æ–‡æ¡£

**é¢„è®¡å·¥ä½œé‡**ï¼š2-3å°æ—¶

---

#### 1.2 åˆ›å»ºå›¾ç‰‡å¤„ç†ä½¿ç”¨æŒ‡å—

**æ–‡ä»¶å**ï¼š`IMAGE_PROCESSING_GUIDE.md`

**å†…å®¹è¦ç‚¹**ï¼š
- å›¾ç‰‡ base64 ç¼–ç æ–¹å¼
- å‰ç«¯å¦‚ä½•å‡†å¤‡å›¾ç‰‡æ•°æ®
- å®Œæ•´çš„ä»£ç ç¤ºä¾‹
- å¸¸è§é—®é¢˜è§£ç­”

**é¢„è®¡å·¥ä½œé‡**ï¼š2å°æ—¶

---

#### 1.3 å‰ç«¯é€‚é…å»ºè®®

**éœ€è¦å‰ç«¯é…åˆ**ï¼š

```javascript
// å‰ç«¯è¯»å–å›¾ç‰‡å¹¶è½¬ base64
function readImageAsBase64(file) {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = (e) => {
            // è·å– base64ï¼ˆç§»é™¤ data:image/xxx;base64, å‰ç¼€ï¼‰
            const base64 = e.target.result.split(',')[1];
            resolve({
                name: file.name,
                content: base64,
                content_type: file.type,
                encoding: 'base64'
            });
        };
        reader.onerror = reject;
        reader.readAsDataURL(file);
    });
}

// æ‰¹é‡å¤„ç†
async function prepareImages(files) {
    const datasets = {};
    for (const file of files) {
        if (file.type.startsWith('image/')) {
            const imageData = await readImageAsBase64(file);
            datasets[file.name] = imageData.content;
        }
    }
    return datasets;
}
```

**é¢„è®¡å·¥ä½œé‡**ï¼šå‰ç«¯ 0.5å¤©

---

## ğŸ“Š äºŒã€Excel åŠŸèƒ½å¢å¼ºï¼ˆP0ï¼‰

### ç°çŠ¶
- âœ… åŸºç¡€ Excel è¯»å–ï¼ˆå• sheetï¼‰
- âŒ ä¸æ”¯æŒå¤š sheet
- âŒ ä¸æ”¯æŒ Excel å†™å…¥

### å»ºè®®ï¼šå®Œæ•´ Excel æ”¯æŒ

#### 2.1 æ·»åŠ  openpyxl ä¾èµ–

**ä¿®æ”¹ requirements.txt**ï¼š
```
openpyxl>=3.1.2
```

#### 2.2 æ›´æ–° sandbox.py

```python
# æ–°å¢åˆ° ALLOWED_MODULES
import openpyxl
from openpyxl import Workbook

ALLOWED_MODULES = {
    # ... ç°æœ‰çš„
    'openpyxl': openpyxl,
    'Workbook': Workbook,
}
```

#### 2.3 åˆ›å»º Excel å¤„ç†æ¨¡æ¿

```python
# æ¨¡æ¿: excel_multi_sheet
"""è¯»å–å¤š sheet Excel"""
import pandas as pd
import io
import base64

for file in selected_files:
    if file['name'].endswith(('.xlsx', '.xls')):
        # è§£ç 
        excel_bytes = base64.b64decode(file['content'])

        # è¯»å–æ‰€æœ‰ sheet
        excel_file = pd.ExcelFile(io.BytesIO(excel_bytes))

        print(f"\næ–‡ä»¶: {file['name']}")
        print(f"Sheet æ•°é‡: {len(excel_file.sheet_names)}")

        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(excel_file, sheet_name=sheet_name)
            print(f"\nSheet: {sheet_name}")
            print(f"  å½¢çŠ¶: {df.shape}")
            print(f"  åˆ—å: {list(df.columns)}")
            print(df.head())
```

**é¢„è®¡å·¥ä½œé‡**ï¼š0.5å¤©ï¼ˆåŒ…æ‹¬æµ‹è¯•ï¼‰

---

## ğŸ“ ä¸‰ã€æ–‡æœ¬å¤„ç†å¢å¼ºï¼ˆP1ï¼‰

### ç°çŠ¶
- âœ… åŸºç¡€æ–‡æœ¬è¯»å–
- âš ï¸ ç¼ºå°‘é«˜çº§æ–‡æœ¬å¤„ç†åŠŸèƒ½

### å»ºè®®ï¼šå¢å¼ºæ–‡æœ¬åˆ†æèƒ½åŠ›

#### 3.1 æ·»åŠ æ–‡æœ¬å¤„ç†åº“

**requirements.txt æ–°å¢**ï¼š
```
jieba>=0.42.1          # ä¸­æ–‡åˆ†è¯
wordcloud>=1.9.3       # è¯äº‘ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
```

#### 3.2 æ›´æ–° sandbox.py

```python
import jieba

ALLOWED_MODULES = {
    # ... ç°æœ‰çš„
    'jieba': jieba,
}
```

#### 3.3 åˆ›å»ºæ–‡æœ¬åˆ†ææ¨¡æ¿

```python
# æ¨¡æ¿: text_word_frequency
"""æ–‡æœ¬è¯é¢‘ç»Ÿè®¡ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰"""
import jieba
from collections import Counter

for file in selected_files:
    if file['name'].endswith('.txt'):
        text = file['content']

        # ä¸­æ–‡åˆ†è¯
        words = jieba.lcut(text)

        # è¿‡æ»¤åœç”¨è¯å’Œæ ‡ç‚¹
        words = [w for w in words if len(w) > 1 and w.isalnum()]

        # è¯é¢‘ç»Ÿè®¡
        word_freq = Counter(words)

        print(f"\næ–‡ä»¶: {file['name']}")
        print(f"æ€»è¯æ•°: {len(words)}")
        print(f"ä¸é‡å¤è¯æ•°: {len(word_freq)}")
        print("\né«˜é¢‘è¯ Top 20:")
        for word, count in word_freq.most_common(20):
            print(f"  {word}: {count}")

# æ¨¡æ¿: text_cleaning
"""æ–‡æœ¬æ¸…æ´—"""
import re

for file in selected_files:
    if file['name'].endswith('.txt'):
        text = file['content']

        # å»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)

        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ï¼‰
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)

        # å»é™¤ç©ºè¡Œ
        lines = [line.strip() for line in text.splitlines() if line.strip()]
        cleaned_text = '\n'.join(lines)

        print(f"\næ–‡ä»¶: {file['name']}")
        print(f"åŸå§‹é•¿åº¦: {len(file['content'])} å­—ç¬¦")
        print(f"æ¸…æ´—åé•¿åº¦: {len(cleaned_text)} å­—ç¬¦")
        print(f"èŠ‚çœ: {(1 - len(cleaned_text)/len(file['content']))*100:.1f}%")
```

**é¢„è®¡å·¥ä½œé‡**ï¼š1å¤©ï¼ˆåŒ…æ‹¬æµ‹è¯•ï¼‰

---

## ğŸ” å››ã€ä»£ç æ‰§è¡Œç›‘æ§å’Œè¯Šæ–­ï¼ˆP1ï¼‰

### å»ºè®®ï¼šå¢å¼ºå¯è§‚æµ‹æ€§

#### 4.1 æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯

**åœ¨ ExecuteResponse ä¸­æ–°å¢å­—æ®µ**ï¼š

```python
class ExecutionStats(BaseModel):
    """æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
    peak_memory_mb: Optional[float] = None      # å³°å€¼å†…å­˜
    cpu_time_ms: Optional[int] = None           # CPU æ—¶é—´
    chart_count: int = 0                         # ç”Ÿæˆå›¾è¡¨æ•°
    dataframe_count: int = 0                     # DataFrame æ•°é‡
    dataset_count: int = 0                       # æ•°æ®é›†æ•°é‡
    code_lines: int = 0                          # ä»£ç è¡Œæ•°

class ExecuteResponse(BaseModel):
    status: str
    execution_time: int
    output: Optional[ExecutionOutput] = None
    error: Optional[str] = None
    stats: Optional[ExecutionStats] = None  # æ–°å¢
```

#### 4.2 æ€§èƒ½ç›‘æ§

```python
import psutil
import os

def execute(self, code: str, datasets=None, preloaded_variables=None):
    # å¼€å§‹ç›‘æ§
    process = psutil.Process(os.getpid())
    start_memory = process.memory_info().rss / 1024 / 1024  # MB

    # æ‰§è¡Œä»£ç ...

    # è®°å½•å³°å€¼å†…å­˜
    peak_memory = process.memory_info().rss / 1024 / 1024

    # è¿”å›ç»Ÿè®¡ä¿¡æ¯
    stats = ExecutionStats(
        peak_memory_mb=peak_memory,
        chart_count=len(charts),
        dataframe_count=len(dataframes),
        dataset_count=len(datasets) if datasets else 0,
        code_lines=len(code.splitlines())
    )
```

**ä¾èµ–**ï¼š
```
psutil>=5.9.8
```

**é¢„è®¡å·¥ä½œé‡**ï¼š1-2å¤©

---

## ğŸ”’ äº”ã€å®‰å…¨æ€§å¢å¼ºï¼ˆP1ï¼‰

### 5.1 ä»£ç å¤æ‚åº¦é™åˆ¶

**ç›®çš„**ï¼šé˜²æ­¢è¿‡äºå¤æ‚çš„ä»£ç æ¶ˆè€—èµ„æº

```python
def validate_code_complexity(code: str) -> tuple[bool, str]:
    """éªŒè¯ä»£ç å¤æ‚åº¦"""

    # é™åˆ¶ä»£ç è¡Œæ•°
    lines = code.splitlines()
    if len(lines) > 500:
        return False, f"ä»£ç è¡Œæ•°è¶…é™ï¼ˆ{len(lines)}/500ï¼‰"

    # é™åˆ¶åµŒå¥—å±‚çº§
    max_indent = 0
    for line in lines:
        if line.strip():
            indent = len(line) - len(line.lstrip())
            max_indent = max(max_indent, indent // 4)

    if max_indent > 10:
        return False, f"ä»£ç åµŒå¥—å±‚çº§è¿‡æ·±ï¼ˆ{max_indent}/10ï¼‰"

    # é™åˆ¶å¾ªç¯æ•°é‡
    loop_count = code.count('for ') + code.count('while ')
    if loop_count > 20:
        return False, f"å¾ªç¯æ•°é‡è¶…é™ï¼ˆ{loop_count}/20ï¼‰"

    return True, ""
```

**é¢„è®¡å·¥ä½œé‡**ï¼š0.5å¤©

---

### 5.2 æ‰§è¡Œæ—¥å¿—å®¡è®¡

**è®°å½•æ‰€æœ‰æ‰§è¡Œ**ï¼š

```python
class ExecutionLog(BaseModel):
    timestamp: datetime
    user_id: Optional[str] = None
    code_hash: str                     # ä»£ç çš„ hash
    status: str                        # success/error/timeout
    execution_time: int
    error: Optional[str] = None

# è®°å½•åˆ°æ•°æ®åº“æˆ–æ—¥å¿—æ–‡ä»¶
def log_execution(log: ExecutionLog):
    # å¯ä»¥å­˜å‚¨åˆ° SQLite/PostgreSQL æˆ–æ—¥å¿—æ–‡ä»¶
    pass
```

**é¢„è®¡å·¥ä½œé‡**ï¼š1å¤©

---

## ğŸ“ˆ å…­ã€æ€§èƒ½ä¼˜åŒ–ï¼ˆP2ï¼‰

### 6.1 ç»“æœç¼“å­˜

**åœºæ™¯**ï¼šç›¸åŒä»£ç å’Œæ•°æ®çš„é‡å¤æ‰§è¡Œ

```python
import hashlib
from functools import lru_cache

class CodeExecutor:
    def __init__(self):
        self.cache = {}  # æˆ–ä½¿ç”¨ Redis

    def _get_cache_key(self, code: str, datasets: Dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{code}:{sorted(datasets.items())}"
        return hashlib.sha256(content.encode()).hexdigest()

    def execute(self, code: str, datasets=None, use_cache=True):
        if use_cache:
            cache_key = self._get_cache_key(code, datasets or {})
            if cache_key in self.cache:
                logger.info("ä½¿ç”¨ç¼“å­˜ç»“æœ")
                return self.cache[cache_key]

        # æ‰§è¡Œä»£ç ...
        result = ...

        if use_cache:
            self.cache[cache_key] = result

        return result
```

**ä¾èµ–**ï¼š
```
redis>=5.0.1  # å¯é€‰ï¼Œç”¨äºåˆ†å¸ƒå¼ç¼“å­˜
```

**é¢„è®¡å·¥ä½œé‡**ï¼š2å¤©

---

### 6.2 å¼‚æ­¥æ‰§è¡Œ

**åœºæ™¯**ï¼šé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡

```python
from fastapi import BackgroundTasks

@app.post("/execute/async")
async def execute_code_async(request: ExecuteRequest, background_tasks: BackgroundTasks):
    """å¼‚æ­¥æ‰§è¡Œä»£ç """

    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = str(uuid.uuid4())

    # æ·»åŠ åˆ°åå°ä»»åŠ¡
    background_tasks.add_task(execute_in_background, task_id, request)

    return {
        "task_id": task_id,
        "status": "pending",
        "message": "ä»»åŠ¡å·²æäº¤"
    }

@app.get("/execute/status/{task_id}")
async def get_execution_status(task_id: str):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    # ä»ç¼“å­˜æˆ–æ•°æ®åº“è·å–ä»»åŠ¡çŠ¶æ€
    return task_status
```

**é¢„è®¡å·¥ä½œé‡**ï¼š2-3å¤©

---

## ğŸ¨ ä¸ƒã€ç”¨æˆ·ä½“éªŒå¢å¼ºï¼ˆP2ï¼‰

### 7.1 ä»£ç è‡ªåŠ¨è¡¥å…¨API

```python
@app.post("/autocomplete")
async def autocomplete(request: AutocompleteRequest):
    """ä»£ç è‡ªåŠ¨è¡¥å…¨"""

    code = request.code
    cursor_position = request.cursor_position

    # ç®€å•çš„è¡¥å…¨é€»è¾‘
    suggestions = []

    # å¦‚æœåœ¨è¾“å…¥ pd.
    if code.endswith('pd.'):
        suggestions = ['read_csv', 'read_json', 'DataFrame', 'Series']

    # å¦‚æœåœ¨è¾“å…¥ df.
    elif code.endswith('df.'):
        suggestions = ['head', 'tail', 'describe', 'info', 'shape', 'columns']

    return {
        "suggestions": suggestions
    }
```

**é¢„è®¡å·¥ä½œé‡**ï¼š1-2å¤©

---

### 7.2 ä»£ç æ ¼å¼åŒ–

```python
@app.post("/format")
async def format_code(request: FormatRequest):
    """æ ¼å¼åŒ–ä»£ç """
    import black

    try:
        formatted = black.format_str(request.code, mode=black.Mode())
        return {
            "formatted_code": formatted,
            "changed": formatted != request.code
        }
    except Exception as e:
        return {
            "error": str(e)
        }
```

**ä¾èµ–**ï¼š
```
black>=24.0.0
```

**é¢„è®¡å·¥ä½œé‡**ï¼š0.5å¤©

---

## ğŸŒ å…«ã€å›½é™…åŒ–æ”¯æŒï¼ˆP3ï¼‰

### å»ºè®®ï¼šå¤šè¯­è¨€é”™è¯¯ä¿¡æ¯

```python
# app/i18n.py
MESSAGES = {
    'zh': {
        'timeout': 'ä»£ç æ‰§è¡Œè¶…æ—¶',
        'syntax_error': 'è¯­æ³•é”™è¯¯',
        'forbidden_operation': 'æ£€æµ‹åˆ°ç¦æ­¢çš„æ“ä½œ',
    },
    'en': {
        'timeout': 'Code execution timeout',
        'syntax_error': 'Syntax error',
        'forbidden_operation': 'Forbidden operation detected',
    }
}

def get_message(key: str, lang: str = 'zh') -> str:
    return MESSAGES.get(lang, MESSAGES['zh']).get(key, key)
```

**é¢„è®¡å·¥ä½œé‡**ï¼š1å¤©

---

## ğŸ“¦ ä¹ã€éƒ¨ç½²å’Œè¿ç»´å¢å¼ºï¼ˆP2ï¼‰

### 9.1 å¥åº·æ£€æŸ¥å¢å¼º

```python
@app.get("/health/detailed")
async def detailed_health_check():
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""

    import psutil

    return {
        "status": "healthy",
        "version": "1.3.0",
        "uptime_seconds": get_uptime(),
        "system": {
            "cpu_percent": psutil.cpu_percent(),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage('/').percent
        },
        "libraries": {
            "numpy": np.__version__,
            "pandas": pd.__version__,
            "sklearn": sklearn.__version__,
        },
        "metrics": {
            "total_executions": execution_count,
            "success_rate": success_rate,
            "avg_execution_time": avg_time
        }
    }
```

**é¢„è®¡å·¥ä½œé‡**ï¼š1å¤©

---

### 9.2 Prometheus æŒ‡æ ‡

```python
from prometheus_client import Counter, Histogram, Gauge

# å®šä¹‰æŒ‡æ ‡
execution_counter = Counter('python_executor_executions_total', 'Total executions')
execution_duration = Histogram('python_executor_duration_seconds', 'Execution duration')
active_executions = Gauge('python_executor_active_executions', 'Active executions')

@app.get("/metrics")
async def metrics():
    """Prometheus æŒ‡æ ‡"""
    from prometheus_client import generate_latest
    return Response(generate_latest(), media_type="text/plain")
```

**ä¾èµ–**ï¼š
```
prometheus-client>=0.19.0
```

**é¢„è®¡å·¥ä½œé‡**ï¼š1å¤©

---

## ğŸ§ª åã€æµ‹è¯•è¦†ç›–å¢å¼ºï¼ˆP1ï¼‰

### 10.1 å•å…ƒæµ‹è¯•

```python
# tests/test_executor.py
import pytest
from app.executor import CodeExecutor

def test_simple_execution():
    executor = CodeExecutor()
    result = executor.execute("print('hello')")
    assert result.status == "success"
    assert "hello" in result.output.stdout

def test_dataset_injection():
    executor = CodeExecutor()
    result = executor.execute(
        "import pandas as pd\ndf = pd.read_csv('data.csv')\nprint(len(df))",
        datasets={"data.csv": "a,b\n1,2\n3,4"}
    )
    assert result.status == "success"
    assert "2" in result.output.stdout

def test_image_processing():
    executor = CodeExecutor()
    # ... æµ‹è¯•å›¾ç‰‡å¤„ç†
```

**æµ‹è¯•è¦†ç›–ç›®æ ‡**ï¼š80%+

**é¢„è®¡å·¥ä½œé‡**ï¼š3-5å¤©

---

### 10.2 é›†æˆæµ‹è¯•

```python
# tests/test_api.py
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_execute_endpoint():
    response = client.post("/execute", json={
        "code": "print('test')"
    })
    assert response.status_code == 200
    assert response.json()["status"] == "success"

def test_with_datasets():
    response = client.post("/execute", json={
        "code": "print(len(selected_files))",
        "datasets": {"test.csv": "a,b\n1,2"}
    })
    assert response.status_code == 200
```

**é¢„è®¡å·¥ä½œé‡**ï¼š2-3å¤©

---

## ğŸ“Š å‡çº§è·¯çº¿å›¾æ€»ç»“

### Phase 1: ç«‹å³å®æ–½ï¼ˆ1-2å‘¨ï¼‰

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | ä»·å€¼ |
|-----|-------|-------|-----|
| å›¾ç‰‡å¤„ç†æ¨¡æ¿ | P0 | 2-3h | â­â­â­â­â­ |
| Excel å¤š sheet | P0 | 0.5å¤© | â­â­â­â­ |
| å›¾ç‰‡å¤„ç†æ–‡æ¡£ | P0 | 2h | â­â­â­â­ |
| å‰ç«¯å›¾ç‰‡é€‚é… | P0 | 0.5å¤© | â­â­â­â­â­ |

**æ€»å·¥ä½œé‡**ï¼šçº¦ 2-3 å¤©
**ROI**ï¼šé«˜ï¼ˆç«‹å³è§£å†³ç”¨æˆ·éœ€æ±‚ï¼‰

---

### Phase 2: è¿‘æœŸè§„åˆ’ï¼ˆ1ä¸ªæœˆï¼‰

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | ä»·å€¼ |
|-----|-------|-------|-----|
| æ–‡æœ¬å¤„ç†å¢å¼º | P1 | 1å¤© | â­â­â­â­ |
| æ‰§è¡Œç›‘æ§ç»Ÿè®¡ | P1 | 1-2å¤© | â­â­â­â­ |
| å®‰å…¨æ€§å¢å¼º | P1 | 1.5å¤© | â­â­â­â­â­ |
| å•å…ƒæµ‹è¯• | P1 | 3-5å¤© | â­â­â­â­ |

**æ€»å·¥ä½œé‡**ï¼šçº¦ 1-2 å‘¨
**ROI**ï¼šä¸­é«˜ï¼ˆæå‡ç¨³å®šæ€§å’Œå®‰å…¨æ€§ï¼‰

---

### Phase 3: ä¸­æœŸè§„åˆ’ï¼ˆ2-3ä¸ªæœˆï¼‰

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | ä»·å€¼ |
|-----|-------|-------|-----|
| ç»“æœç¼“å­˜ | P2 | 2å¤© | â­â­â­ |
| å¼‚æ­¥æ‰§è¡Œ | P2 | 2-3å¤© | â­â­â­â­ |
| ä»£ç è¡¥å…¨ | P2 | 1-2å¤© | â­â­â­ |
| ç›‘æ§æŒ‡æ ‡ | P2 | 1å¤© | â­â­â­ |

**æ€»å·¥ä½œé‡**ï¼šçº¦ 1-2 å‘¨
**ROI**ï¼šä¸­ï¼ˆæ€§èƒ½å’Œä½“éªŒæå‡ï¼‰

---

### Phase 4: é•¿æœŸè§„åˆ’ï¼ˆ3-6ä¸ªæœˆï¼‰

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ | ä»·å€¼ |
|-----|-------|-------|-----|
| å›½é™…åŒ– | P3 | 1å¤© | â­â­ |
| é«˜çº§ç¼“å­˜ | P3 | 3å¤© | â­â­â­ |
| åˆ†å¸ƒå¼æ‰§è¡Œ | P3 | 5å¤©+ | â­â­â­ |

---

## ğŸ¯ æ¨èå®æ–½é¡ºåº

### Week 1-2ï¼ˆç«‹å³ï¼‰
1. âœ… åˆ›å»ºå›¾ç‰‡å¤„ç†æ¨¡æ¿ï¼ˆ4ä¸ªï¼‰
2. âœ… ç¼–å†™å›¾ç‰‡å¤„ç†æ–‡æ¡£
3. âœ… Excel å¤š sheet æ”¯æŒ
4. âœ… å‰ç«¯å›¾ç‰‡ base64 é€‚é…

### Week 3-4
1. æ–‡æœ¬å¤„ç†å¢å¼ºï¼ˆjieba åˆ†è¯ï¼‰
2. æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
3. ä»£ç å¤æ‚åº¦é™åˆ¶

### Month 2
1. å•å…ƒæµ‹è¯•è¦†ç›–
2. é›†æˆæµ‹è¯•
3. æ€§èƒ½åŸºå‡†æµ‹è¯•

### Month 3
1. ç»“æœç¼“å­˜
2. å¼‚æ­¥æ‰§è¡Œæ”¯æŒ
3. Prometheus ç›‘æ§

---

## ğŸ“ å…·ä½“è¡ŒåŠ¨å»ºè®®

### ä»Šå¤©å°±å¯ä»¥åšçš„ï¼ˆ1å°æ—¶å†…ï¼‰

1. **æ·»åŠ å›¾ç‰‡å¤„ç†æ¨¡æ¿**
   - åœ¨ `app/sandbox.py` çš„ `CODE_TEMPLATES` æ·»åŠ  4 ä¸ªå›¾ç‰‡å¤„ç†æ¨¡æ¿
   - ç«‹å³å¯ç”¨ï¼Œæ— éœ€å…¶ä»–æ”¹åŠ¨

2. **æ›´æ–° README**
   - æ·»åŠ å›¾ç‰‡å¤„ç†åŠŸèƒ½è¯´æ˜
   - æ›´æ–°åŠŸèƒ½åˆ—è¡¨

3. **åˆ›å»ºå›¾ç‰‡å¤„ç†ç¤ºä¾‹æ–‡æ¡£**
   - ç¤ºä¾‹ä»£ç 
   - ä½¿ç”¨è¯´æ˜

### æœ¬å‘¨å¯ä»¥å®Œæˆçš„

1. **Excel å¤š sheet æ”¯æŒ**
   - æ·»åŠ  openpyxl ä¾èµ–
   - æ›´æ–° sandbox.py
   - åˆ›å»ºæµ‹è¯•ç”¨ä¾‹

2. **å‰ç«¯é€‚é…æŒ‡å¯¼**
   - ç¼–å†™å‰ç«¯å›¾ç‰‡å¤„ç†æ–‡æ¡£
   - æä¾› JavaScript ç¤ºä¾‹ä»£ç 
   - ä¸å‰ç«¯å›¢é˜Ÿæ²Ÿé€š

---

## ğŸ’¡ åˆ›æ–°æ€§å»ºè®®

### 1. AI ä»£ç åŠ©æ‰‹é›†æˆï¼ˆæœªæ¥ï¼‰

```python
@app.post("/ai/suggest")
async def ai_code_suggestion(request: AISuggestRequest):
    """AI ä»£ç å»ºè®®"""
    # åŸºäºç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆä»£ç å»ºè®®
    # å¯ä»¥é›†æˆ GPT-4 æˆ–æœ¬åœ°æ¨¡å‹
    pass
```

### 2. ä»£ç æ¨¡æ¿å¸‚åœº

- ç”¨æˆ·å¯ä»¥åˆ†äº«è‡ªå·±çš„ä»£ç æ¨¡æ¿
- è¯„åˆ†å’Œè¯„è®ºç³»ç»Ÿ
- æ¨¡æ¿åˆ†ç±»å’Œæœç´¢

### 3. å¯è§†åŒ–å·¥ä½œæµ

- æ‹–æ‹½å¼æ•°æ®å¤„ç†æµç¨‹
- è‡ªåŠ¨ç”Ÿæˆ Python ä»£ç 
- ç±»ä¼¼ Orange æˆ– KNIME

---

## âœ… æ€»ç»“

### å½“å‰ä¼˜åŠ¿
- âœ… æ ¸å¿ƒåŠŸèƒ½å®Œå–„
- âœ… å®‰å…¨æ€§è‰¯å¥½
- âœ… å›¾ç‰‡åº“å·²æ”¯æŒ
- âœ… æ™ºèƒ½ç¼©è¿›ç®—æ³•
- âœ… åŒæ ¼å¼æ•°æ®ä¼ é€’

### ä¸»è¦æ”¹è¿›æ–¹å‘
1. **å›¾ç‰‡å¤„ç†**ï¼šæ·»åŠ æ¨¡æ¿å’Œæ–‡æ¡£ï¼ˆP0ï¼‰
2. **Excel å¢å¼º**ï¼šå¤š sheet æ”¯æŒï¼ˆP0ï¼‰
3. **æ–‡æœ¬åˆ†æ**ï¼šjieba åˆ†è¯ï¼ˆP1ï¼‰
4. **ç›‘æ§ç»Ÿè®¡**ï¼šæ€§èƒ½æŒ‡æ ‡ï¼ˆP1ï¼‰
5. **æµ‹è¯•è¦†ç›–**ï¼šå•å…ƒ+é›†æˆæµ‹è¯•ï¼ˆP1ï¼‰

### é¢„æœŸæ•ˆæœ
- ğŸ¯ åŠŸèƒ½å®Œæ•´åº¦ï¼š90%+
- ğŸ”’ å®‰å…¨æ€§ï¼š95%+
- âš¡ æ€§èƒ½ï¼šä¼˜ç§€
- ğŸ“Š å¯è§‚æµ‹æ€§ï¼šè‰¯å¥½
- ğŸ§ª æµ‹è¯•è¦†ç›–ï¼š80%+

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0
**åˆ›å»ºæ—¥æœŸ**: 2025-11-03
**çŠ¶æ€**: å»ºè®®ä¸­
**é¢„è®¡å®Œæˆæ—¶é—´**: Phase 1-2 çº¦ 1-1.5 ä¸ªæœˆ
