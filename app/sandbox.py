"""
å®‰å…¨æ²™ç®±é…ç½®
"""
import sys
from typing import Dict, Any
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import plotly
import plotly.graph_objects as go
import plotly.express as px
import sklearn
from sklearn import preprocessing, model_selection, metrics, linear_model, ensemble, tree
import seaborn as sns
import scipy
from scipy import stats
import PIL
import PIL.Image
import PIL.ImageEnhance
import PIL.ImageFilter
import io
import base64
import json
import re as regex_module
from collections import Counter
import openpyxl
from openpyxl import Workbook

# é…ç½® matplotlib ä½¿ç”¨éäº¤äº’å¼åç«¯
matplotlib.use('Agg')


class SafeExecutionEnvironment:
    """å®‰å…¨æ‰§è¡Œç¯å¢ƒ"""

    # å…è®¸çš„åº“ç™½åå•ï¼ˆé¢„å¯¼å…¥ï¼‰
    ALLOWED_MODULES = {
        'numpy': np,
        'np': np,
        'pandas': pd,
        'pd': pd,
        'matplotlib': matplotlib,
        'plt': plt,
        'plotly': plotly,
        'go': go,
        'px': px,
        'sklearn': sklearn,
        'seaborn': sns,
        'sns': sns,
        'scipy': scipy,
        'Image': PIL.Image,
        'ImageEnhance': PIL.ImageEnhance,
        'ImageFilter': PIL.ImageFilter,
        'io': io,
        'base64': base64,
        'json': json,
        're': regex_module,
        'Counter': Counter,
        'openpyxl': openpyxl,
        'Workbook': Workbook,
    }

    # ç¦æ­¢çš„æ“ä½œå’Œæ¨¡å—
    FORBIDDEN_NAMES = [
        'file', 'input', 'raw_input',
        'compile', 'reload', '__import__',
        'execfile', 'eval', 'exec',
        'os', 'sys', 'subprocess', 'socket',
        'urllib', 'requests', 'http', 'httpx',
        'pathlib', 'shutil', 'glob',
    ]

    # ç¦æ­¢çš„ import æ¨¡å—
    FORBIDDEN_IMPORTS = [
        'os', 'sys', 'subprocess', 'socket',
        'urllib', 'requests', 'http', 'httpx',
        'pathlib', 'shutil', 'glob', 'pickle',
        'multiprocessing', 'threading', 'asyncio',
    ]

    @classmethod
    def safe_import(cls, name, globals=None, locals=None, fromlist=(), level=0):
        """
        å®‰å…¨çš„ import å‡½æ•°
        åªå…è®¸å¯¼å…¥ç™½åå•ä¸­çš„æ¨¡å—ï¼Œå¹¶è¿”å›é¢„å…ˆå¯¼å…¥çš„å¯¹è±¡
        å…è®¸å†…éƒ¨ä¾èµ–çš„å¯¼å…¥ï¼Œä½†é˜»æ­¢ç¦æ­¢çš„æ¨¡å—
        """
        import logging
        logger = logging.getLogger(__name__)
        logger.debug(f"safe_import called: name={name}, fromlist={fromlist}, level={level}")

        base_module = name.split('.')[0]

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¦æ­¢çš„æ¨¡å—
        if base_module in cls.FORBIDDEN_IMPORTS or name in cls.FORBIDDEN_IMPORTS:
            raise ImportError(f"ä¸å…è®¸å¯¼å…¥æ¨¡å—: {name}")

        # å…è®¸çš„æ¨¡å—æ˜ å°„ï¼ˆè¿”å›å·²ç»å¯¼å…¥çš„å¯¹è±¡ï¼‰
        allowed_mapping = {
            'numpy': np,
            'pandas': pd,
            'matplotlib': matplotlib,
            'matplotlib.pyplot': plt,
            'plotly': plotly,
            'plotly.graph_objects': go,
            'plotly.express': px,
            'sklearn': sklearn,
            'seaborn': sns,
            'scipy': scipy,
            'PIL': PIL,
            'PIL.Image': PIL.Image,
            'PIL.ImageEnhance': PIL.ImageEnhance,
            'PIL.ImageFilter': PIL.ImageFilter,
            'io': io,
            'base64': base64,
            'json': json,
            're': regex_module,
            'collections': Counter,
        }

        # å¤„ç†å…è®¸çš„åº“
        if base_module in ['matplotlib', 'plotly', 'numpy', 'pandas', 'sklearn', 'seaborn', 'scipy', 'PIL', 'io', 'base64', 'json', 're', 'collections']:
            # å¯¹äº "import matplotlib.pyplot as plt" è¿™ç§æƒ…å†µ
            # fromlist ä¸ºç©ºï¼Œéœ€è¦è¿”å›é¡¶å±‚æ¨¡å—ï¼ˆmatplotlibï¼‰
            # Python ä¼šè‡ªåŠ¨å¤„ç† matplotlib.pyplot çš„è®¿é—®
            if not fromlist:
                # æ²¡æœ‰ fromlistï¼Œè¿”å›é¡¶å±‚æ¨¡å—
                logger.debug(f"Returning top-level module for {base_module}")
                if base_module in allowed_mapping:
                    return allowed_mapping[base_module]

            # å¯¹äº "from matplotlib import pyplot" æˆ– "from sklearn.preprocessing import StandardScaler"
            # fromlist ä¸ä¸ºç©ºï¼Œéœ€è¦è¿”å›è¯·æ±‚çš„æ¨¡å—
            else:
                logger.debug(f"Returning module {name} with fromlist {fromlist}")
                # å¦‚æœå®Œæ•´åç§°åœ¨æ˜ å°„ä¸­ï¼Œè¿”å›å®ƒ
                if name in allowed_mapping:
                    return allowed_mapping[name]

            # å°è¯•å®é™…å¯¼å…¥ï¼ˆæ”¯æŒå­æ¨¡å—ï¼Œå¦‚ sklearn.preprocessingï¼‰
            try:
                logger.debug(f"Attempting real import of {name}")
                result = __import__(name, globals, locals, fromlist, level)
                logger.debug(f"Import successful, returning module")
                return result
            except ImportError as e:
                logger.debug(f"Import failed: {e}")
                # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œè¿”å›åŸºç¡€æ¨¡å—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                if base_module in allowed_mapping:
                    logger.debug(f"Fallback to base module {base_module}")
                    return allowed_mapping[base_module]
                raise

        # å¯¹äºå…¶ä»–æ¨¡å—ï¼ˆåŒ…æ‹¬åº“çš„å†…éƒ¨ä¾èµ–ï¼‰ï¼Œå…è®¸æ­£å¸¸å¯¼å…¥
        # ä½†è¦ç¡®ä¿ä¸æ˜¯ç¦æ­¢çš„æ¨¡å—
        try:
            return __import__(name, globals, locals, fromlist, level)
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªç©ºçš„æ¨¡å—å¯¹è±¡ï¼ˆé¿å…ä¸­æ–­æ‰§è¡Œï¼‰
            import types
            return types.ModuleType(name)

    @classmethod
    def get_safe_globals(cls) -> Dict[str, Any]:
        """è·å–å®‰å…¨çš„å…¨å±€å‘½åç©ºé—´"""
        # åˆ›å»ºå®‰å…¨çš„ builtins
        safe_builtins = {
            # åŸºç¡€å‡½æ•°
            'print': print,
            'len': len,
            'range': range,
            'enumerate': enumerate,
            'zip': zip,
            'map': map,
            'filter': filter,
            'sum': sum,
            'min': min,
            'max': max,
            'abs': abs,
            'round': round,
            'sorted': sorted,
            'reversed': reversed,
            'list': list,
            'tuple': tuple,
            'dict': dict,
            'set': set,
            'frozenset': frozenset,
            'str': str,
            'int': int,
            'float': float,
            'bool': bool,
            'bytes': bytes,
            # ç±»å‹æ£€æŸ¥
            'type': type,
            'isinstance': isinstance,
            'issubclass': issubclass,
            'hasattr': hasattr,
            'getattr': getattr,
            'setattr': setattr,
            # å…¶ä»–å®‰å…¨å‡½æ•°
            'any': any,
            'all': all,
            'ord': ord,
            'chr': chr,
            'hex': hex,
            'oct': oct,
            'bin': bin,
            'pow': pow,
            'divmod': divmod,
            # å¼‚å¸¸
            'Exception': Exception,
            'ValueError': ValueError,
            'TypeError': TypeError,
            'KeyError': KeyError,
            'IndexError': IndexError,
            'AttributeError': AttributeError,
            'RuntimeError': RuntimeError,
            'StopIteration': StopIteration,
            # æ§åˆ¶ import
            '__import__': cls.safe_import,
            # å¸¸é‡
            'True': True,
            'False': False,
            'None': None,
        }

        safe_dict = {
            '__builtins__': safe_builtins,
            '__name__': '__main__',
            '__doc__': None,
        }

        # é¢„å…ˆæ·»åŠ å…è®¸çš„æ¨¡å—ï¼ˆæ— éœ€ import å³å¯ä½¿ç”¨ï¼‰
        safe_dict.update(cls.ALLOWED_MODULES)

        return safe_dict

    @classmethod
    def validate_code(cls, code: str) -> tuple[bool, str]:
        """
        éªŒè¯ä»£ç æ˜¯å¦å®‰å…¨

        Returns:
            (is_valid, error_message)
        """
        import re

        if not code or not code.strip():
            return False, "ä»£ç ä¸èƒ½ä¸ºç©º"

        # æ£€æŸ¥ä»£ç é•¿åº¦
        if len(code) > 100000:  # 100KB
            return False, "ä»£ç è¿‡é•¿ï¼ˆæœ€å¤§100KBï¼‰"

        # æ£€æŸ¥ç¦æ­¢çš„å…³é”®å­—ï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›´ç²¾ç¡®åœ°åŒ¹é…ï¼‰
        for forbidden in cls.FORBIDDEN_NAMES:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å‡½æ•°è°ƒç”¨ï¼Œé¿å…è¯¯æŠ¥
            # ä¾‹å¦‚ï¼šåŒ¹é… "open(" ä½†ä¸åŒ¹é… "reopen("
            pattern = r'\b' + re.escape(forbidden) + r'\s*\('
            if re.search(pattern, code, re.IGNORECASE):
                return False, f"æ£€æµ‹åˆ°ç¦æ­¢çš„æ“ä½œ: {forbidden}()\nå®‰å…¨ç­–ç•¥ä¸å…è®¸ä½¿ç”¨æ­¤å‡½æ•°ã€‚"

        # æ£€æŸ¥ç¦æ­¢çš„ importï¼ˆæ”¹è¿›çš„æ£€æµ‹ï¼‰
        lines = code.split('\n')
        for line_no, line in enumerate(lines, 1):
            line_stripped = line.strip()

            # è·³è¿‡æ³¨é‡Š
            if line_stripped.startswith('#'):
                continue

            # æ£€æŸ¥ import è¯­å¥
            if line_stripped.startswith('import ') or line_stripped.startswith('from '):
                if line_stripped.startswith('import '):
                    # å¤„ç† import è¯­å¥: import os, sys
                    import_part = line_stripped[7:].split('#')[0].strip()  # ç§»é™¤æ³¨é‡Š
                    modules = [m.strip().split()[0].split('.')[0] for m in import_part.split(',')]

                    for module in modules:
                        if module in cls.FORBIDDEN_IMPORTS:
                            return False, f"ç¬¬{line_no}è¡Œï¼šç¦æ­¢å¯¼å…¥æ¨¡å— '{module}'\nå®‰å…¨ç­–ç•¥ä¸å…è®¸ä½¿ç”¨æ­¤æ¨¡å—ã€‚"

                elif line_stripped.startswith('from '):
                    # å¤„ç† from è¯­å¥: from os import path
                    parts = line_stripped[5:].split('#')[0].strip().split()
                    if parts:
                        module = parts[0].split('.')[0]
                        if module in cls.FORBIDDEN_IMPORTS:
                            return False, f"ç¬¬{line_no}è¡Œï¼šç¦æ­¢å¯¼å…¥æ¨¡å— '{module}'\nå®‰å…¨ç­–ç•¥ä¸å…è®¸ä½¿ç”¨æ­¤æ¨¡å—ã€‚"

        # å°è¯•ç¼–è¯‘
        try:
            compile(code, '<string>', 'exec')
            return True, ""
        except SyntaxError as e:
            # æä¾›æ›´å‹å¥½çš„è¯­æ³•é”™è¯¯ä¿¡æ¯
            error_msg = f"è¯­æ³•é”™è¯¯"
            if e.lineno:
                error_msg += f"ï¼ˆç¬¬{e.lineno}è¡Œï¼‰"
            if e.msg:
                error_msg += f": {e.msg}"
            if e.text:
                error_msg += f"\né—®é¢˜ä»£ç : {e.text.strip()}"
                if e.offset:
                    error_msg += f"\n{' ' * (e.offset - 1)}^"

            return False, error_msg
        except IndentationError as e:
            # ç¼©è¿›é”™è¯¯
            error_msg = f"ç¼©è¿›é”™è¯¯"
            if e.lineno:
                error_msg += f"ï¼ˆç¬¬{e.lineno}è¡Œï¼‰"
            error_msg += f": {e.msg}"
            return False, error_msg
        except Exception as e:
            return False, f"ç¼–è¯‘é”™è¯¯: {str(e)}"

    @classmethod
    def compile_code(cls, code: str):
        """ç¼–è¯‘ä»£ç """
        return compile(code, '<string>', 'exec')


# é¢„å®šä¹‰çš„ä»£ç æ¨¡æ¿
CODE_TEMPLATES = {
    "matplotlib_basic": """import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.figure(figsize=(10, 6))
plt.plot(x, y)
plt.title('Sine Wave')
plt.xlabel('X')
plt.ylabel('Y')
plt.grid(True)
plt.show()
""",

    "plotly_scatter": """import plotly.express as px
import pandas as pd

df = pd.DataFrame({
    'x': [1, 2, 3, 4, 5],
    'y': [2, 4, 1, 5, 3],
    'category': ['A', 'B', 'A', 'B', 'A']
})

fig = px.scatter(df, x='x', y='y', color='category', title='Scatter Plot')
fig.show()
""",

    "pandas_analysis": """import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': [25, 30, 35, 28],
    'Score': [85, 92, 78, 88]
})

print("æ•°æ®æ¦‚è§ˆ:")
print(df)
print("\\nç»Ÿè®¡ä¿¡æ¯:")
print(df.describe())
""",

    "sklearn_preprocessing": """from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
data = pd.DataFrame({
    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'feature2': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],
    'target': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
})

# åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
X = data[['feature1', 'feature2']]
y = data['target']

# æ•°æ®åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("åŸå§‹æ•°æ®:")
print(X_train.head())
print("\\næ ‡å‡†åŒ–å:")
print(pd.DataFrame(X_train_scaled, columns=X.columns).head())
""",

    "sklearn_linear_regression": """from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# ç”Ÿæˆç¤ºä¾‹æ•°æ®
np.random.seed(42)
X = np.random.rand(100, 1) * 10
y = 2.5 * X + 1.5 + np.random.randn(100, 1) * 2

# è®­ç»ƒæ¨¡å‹
model = LinearRegression()
model.fit(X, y)

# é¢„æµ‹
y_pred = model.predict(X)

# è¯„ä¼°
print(f"ç³»æ•°: {model.coef_[0][0]:.2f}")
print(f"æˆªè·: {model.intercept_[0]:.2f}")
print(f"RÂ² åˆ†æ•°: {r2_score(y, y_pred):.3f}")
print(f"å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_pred):.3f}")

# å¯è§†åŒ–
plt.figure(figsize=(10, 6))
plt.scatter(X, y, alpha=0.5, label='æ•°æ®ç‚¹')
plt.plot(X, y_pred, 'r-', linewidth=2, label='æ‹Ÿåˆçº¿')
plt.xlabel('X')
plt.ylabel('y')
plt.title('çº¿æ€§å›å½’ç¤ºä¾‹')
plt.legend()
plt.grid(True)
plt.show()
""",

    "sklearn_classification": """from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd
import numpy as np

# åˆ›å»ºåˆ†ç±»æ•°æ®
np.random.seed(42)
n_samples = 200
X = np.random.randn(n_samples, 4)
y = (X[:, 0] + X[:, 1] > 0).astype(int)

# åˆ†å‰²æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# è®­ç»ƒéšæœºæ£®æ—
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# é¢„æµ‹
y_pred = clf.predict(X_test)

# è¯„ä¼°
print(f"å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.3f}")
print("\\nåˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test, y_pred))
print("\\nç‰¹å¾é‡è¦æ€§:")
for i, importance in enumerate(clf.feature_importances_):
    print(f"ç‰¹å¾ {i}: {importance:.3f}")
""",

    "seaborn_visualization": """import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# è®¾ç½®æ ·å¼
sns.set_theme(style="whitegrid")

# åˆ›å»ºç¤ºä¾‹æ•°æ®
np.random.seed(42)
df = pd.DataFrame({
    'x': np.random.randn(100),
    'y': np.random.randn(100),
    'category': np.random.choice(['A', 'B', 'C'], 100),
    'value': np.random.rand(100) * 100
})

# åˆ›å»ºå¤šå­å›¾
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# æ•£ç‚¹å›¾
sns.scatterplot(data=df, x='x', y='y', hue='category', size='value',
                ax=axes[0, 0], alpha=0.6)
axes[0, 0].set_title('æ•£ç‚¹å›¾')

# ç®±çº¿å›¾
sns.boxplot(data=df, x='category', y='value', ax=axes[0, 1])
axes[0, 1].set_title('ç®±çº¿å›¾')

# å°æç´å›¾
sns.violinplot(data=df, x='category', y='value', ax=axes[1, 0])
axes[1, 0].set_title('å°æç´å›¾')

# ç›´æ–¹å›¾
sns.histplot(data=df, x='value', hue='category', ax=axes[1, 1], kde=True)
axes[1, 1].set_title('ç›´æ–¹å›¾')

plt.tight_layout()
plt.show()
""",

    "scipy_stats": """from scipy import stats
import numpy as np
import matplotlib.pyplot as plt

# ç”Ÿæˆæ•°æ®
np.random.seed(42)
data1 = np.random.normal(100, 15, 100)
data2 = np.random.normal(105, 15, 100)

# æè¿°æ€§ç»Ÿè®¡
print("æ•°æ®1ç»Ÿè®¡:")
print(f"å‡å€¼: {np.mean(data1):.2f}")
print(f"æ ‡å‡†å·®: {np.std(data1):.2f}")
print(f"ååº¦: {stats.skew(data1):.2f}")
print(f"å³°åº¦: {stats.kurtosis(data1):.2f}")

# tæ£€éªŒ
t_stat, p_value = stats.ttest_ind(data1, data2)
print(f"\\ntæ£€éªŒç»“æœ:")
print(f"tç»Ÿè®¡é‡: {t_stat:.3f}")
print(f"på€¼: {p_value:.3f}")
print(f"ç»“è®º: {'æ˜¾è‘—å·®å¼‚' if p_value < 0.05 else 'æ— æ˜¾è‘—å·®å¼‚'}")

# æ­£æ€æ€§æ£€éªŒ
stat, p = stats.normaltest(data1)
print(f"\\næ­£æ€æ€§æ£€éªŒ:")
print(f"på€¼: {p:.3f}")
print(f"ç»“è®º: {'ç¬¦åˆæ­£æ€åˆ†å¸ƒ' if p > 0.05 else 'ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒ'}")

# å¯è§†åŒ–
plt.figure(figsize=(10, 6))
plt.hist(data1, bins=20, alpha=0.5, label='æ•°æ®1', density=True)
plt.hist(data2, bins=20, alpha=0.5, label='æ•°æ®2', density=True)
plt.xlabel('å€¼')
plt.ylabel('é¢‘ç‡')
plt.title('æ•°æ®åˆ†å¸ƒå¯¹æ¯”')
plt.legend()
plt.grid(True)
plt.show()
""",

    "image_format_convert": """from PIL import Image
import io
import base64

print("=" * 60)
print("æ‰¹é‡å›¾ç‰‡æ ¼å¼è½¬æ¢")
print("=" * 60)

converted_count = 0

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):
        try:
            # è§£ç å›¾ç‰‡
            img_data = base64.b64decode(file['content'])
            img = Image.open(io.BytesIO(img_data))

            original_format = img.format
            original_size = len(img_data)

            # è½¬æ¢ä¸º PNG æ ¼å¼
            output = io.BytesIO()
            if img.mode == 'RGBA':
                img.save(output, format='PNG')
            else:
                # è½¬æ¢ä¸º RGB æ¨¡å¼åä¿å­˜ä¸º PNG
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                img.save(output, format='PNG')

            new_size = output.tell()
            new_name = file['name'].rsplit('.', 1)[0] + '.png'

            print(f"âœ“ {file['name']}")
            print(f"  {original_format} -> PNG")
            print(f"  {original_size/1024:.1f}KB -> {new_size/1024:.1f}KB")

            converted_count += 1

        except Exception as e:
            print(f"âœ— {file['name']}: {e}")

print(f"\\næˆåŠŸè½¬æ¢ {converted_count} ä¸ªæ–‡ä»¶")
""",

    "image_compress": """from PIL import Image
import io
import base64

print("=" * 60)
print("æ‰¹é‡å›¾ç‰‡å‹ç¼©")
print("=" * 60)

# é…ç½®å‚æ•°
MAX_SIZE = (1920, 1080)  # æœ€å¤§å°ºå¯¸
QUALITY = 85              # JPEG è´¨é‡

compressed_count = 0
total_saved = 0

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
        try:
            # è§£ç å›¾ç‰‡
            img_data = base64.b64decode(file['content'])
            img = Image.open(io.BytesIO(img_data))

            original_size = len(img_data)
            original_dimension = img.size

            # è°ƒæ•´å°ºå¯¸ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
            img.thumbnail(MAX_SIZE, Image.Resampling.LANCZOS)

            # å‹ç¼©ä¿å­˜
            output = io.BytesIO()
            if img.mode == 'RGBA':
                img = img.convert('RGB')
            img.save(output, format='JPEG', quality=QUALITY, optimize=True)

            new_size = output.tell()
            saved = original_size - new_size
            saved_percent = (saved / original_size) * 100

            print(f"âœ“ {file['name']}")
            print(f"  å°ºå¯¸: {original_dimension} -> {img.size}")
            print(f"  å¤§å°: {original_size/1024:.1f}KB -> {new_size/1024:.1f}KB")
            print(f"  èŠ‚çœ: {saved/1024:.1f}KB ({saved_percent:.1f}%)")

            compressed_count += 1
            total_saved += saved

        except Exception as e:
            print(f"âœ— {file['name']}: {e}")

print(f"\\næˆåŠŸå‹ç¼© {compressed_count} ä¸ªæ–‡ä»¶")
print(f"æ€»å…±èŠ‚çœ: {total_saved/1024/1024:.2f}MB")
""",

    "image_analysis": """from PIL import Image
import io
import base64
import numpy as np

print("=" * 60)
print("å›¾ç‰‡æ•°æ®é›†åˆ†ææŠ¥å‘Š")
print("=" * 60)

image_stats = {
    'count': 0,
    'formats': {},
    'modes': {},
    'sizes': [],
    'file_sizes': [],
}

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff')):
        try:
            img_data = base64.b64decode(file['content'])
            img = Image.open(io.BytesIO(img_data))

            # ç»Ÿè®¡ä¿¡æ¯
            image_stats['count'] += 1

            # æ ¼å¼ç»Ÿè®¡
            fmt = img.format or 'Unknown'
            image_stats['formats'][fmt] = image_stats['formats'].get(fmt, 0) + 1

            # é¢œè‰²æ¨¡å¼ç»Ÿè®¡
            mode = img.mode
            image_stats['modes'][mode] = image_stats['modes'].get(mode, 0) + 1

            # å°ºå¯¸ç»Ÿè®¡
            image_stats['sizes'].append(img.size)

            # æ–‡ä»¶å¤§å°ç»Ÿè®¡
            image_stats['file_sizes'].append(len(img_data))

        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åˆ†æ {file['name']}: {e}")

if image_stats['count'] > 0:
    print(f"\\nğŸ“Š æ€»å›¾ç‰‡æ•°: {image_stats['count']}")

    print(f"\\nğŸ“ æ ¼å¼åˆ†å¸ƒ:")
    for fmt, count in sorted(image_stats['formats'].items()):
        percentage = (count / image_stats['count']) * 100
        print(f"  {fmt}: {count} ({percentage:.1f}%)")

    print(f"\\nğŸ¨ é¢œè‰²æ¨¡å¼:")
    for mode, count in sorted(image_stats['modes'].items()):
        print(f"  {mode}: {count}")

    if image_stats['sizes']:
        widths = [s[0] for s in image_stats['sizes']]
        heights = [s[1] for s in image_stats['sizes']]

        print(f"\\nğŸ“ å°ºå¯¸ç»Ÿè®¡:")
        print(f"  å®½åº¦: æœ€å°={min(widths)}, æœ€å¤§={max(widths)}, å¹³å‡={int(np.mean(widths))}")
        print(f"  é«˜åº¦: æœ€å°={min(heights)}, æœ€å¤§={max(heights)}, å¹³å‡={int(np.mean(heights))}")

    if image_stats['file_sizes']:
        sizes_kb = [s/1024 for s in image_stats['file_sizes']]
        print(f"\\nğŸ’¾ æ–‡ä»¶å¤§å°:")
        print(f"  æœ€å°: {min(sizes_kb):.1f}KB")
        print(f"  æœ€å¤§: {max(sizes_kb):.1f}KB")
        print(f"  å¹³å‡: {np.mean(sizes_kb):.1f}KB")
        print(f"  æ€»è®¡: {sum(sizes_kb)/1024:.2f}MB")

else:
    print("\\næœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
""",

    "image_enhance": """from PIL import Image, ImageEnhance
import io
import base64

print("=" * 60)
print("æ‰¹é‡å›¾ç‰‡å¢å¼ºå¤„ç†")
print("=" * 60)

# å¢å¼ºå‚æ•°
BRIGHTNESS_FACTOR = 1.2   # äº®åº¦å¢å¼ºï¼ˆ1.0 = åŸå§‹ï¼‰
CONTRAST_FACTOR = 1.1     # å¯¹æ¯”åº¦å¢å¼º
SHARPNESS_FACTOR = 1.5    # é”åŒ–

enhanced_count = 0

for file in selected_files:
    if file['name'].lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
        try:
            # è§£ç å›¾ç‰‡
            img_data = base64.b64decode(file['content'])
            img = Image.open(io.BytesIO(img_data))

            # 1. äº®åº¦å¢å¼º
            enhancer = ImageEnhance.Brightness(img)
            img = enhancer.enhance(BRIGHTNESS_FACTOR)

            # 2. å¯¹æ¯”åº¦å¢å¼º
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(CONTRAST_FACTOR)

            # 3. é”åŒ–
            enhancer = ImageEnhance.Sharpness(img)
            img = enhancer.enhance(SHARPNESS_FACTOR)

            print(f"âœ“ {file['name']}")
            print(f"  äº®åº¦: +{(BRIGHTNESS_FACTOR-1)*100:.0f}%")
            print(f"  å¯¹æ¯”åº¦: +{(CONTRAST_FACTOR-1)*100:.0f}%")
            print(f"  é”åŒ–: +{(SHARPNESS_FACTOR-1)*100:.0f}%")

            enhanced_count += 1

        except Exception as e:
            print(f"âœ— {file['name']}: {e}")

print(f"\\næˆåŠŸå¢å¼º {enhanced_count} ä¸ªæ–‡ä»¶")
""",

    "excel_multi_sheet": """import pandas as pd
import io
import base64

print("=" * 60)
print("Excel å¤š Sheet è¯»å–å’Œåˆ†æ")
print("=" * 60)

excel_count = 0

for file in selected_files:
    if file['name'].endswith(('.xlsx', '.xls')):
        try:
            # è§£ç  Excel æ–‡ä»¶
            excel_bytes = base64.b64decode(file['content'])

            # è¯»å–æ‰€æœ‰ sheet
            excel_file = pd.ExcelFile(io.BytesIO(excel_bytes))

            print(f"\\næ–‡ä»¶: {file['name']}")
            print(f"Sheet æ•°é‡: {len(excel_file.sheet_names)}")
            print(f"Sheet åˆ—è¡¨: {', '.join(excel_file.sheet_names)}")

            # è¯»å–æ¯ä¸ª sheet
            for i, sheet_name in enumerate(excel_file.sheet_names, 1):
                df = pd.read_excel(excel_file, sheet_name=sheet_name)

                print(f"\\n[{i}] Sheet: {sheet_name}")
                print(f"    å½¢çŠ¶: {df.shape}")
                print(f"    åˆ—å: {list(df.columns)}")

                # æ˜¾ç¤ºå‰å‡ è¡Œ
                print(f"    æ•°æ®é¢„è§ˆ:")
                print(df.head(3).to_string(index=False))

                # åŸºç¡€ç»Ÿè®¡
                numeric_cols = df.select_dtypes(include=['number']).columns
                if len(numeric_cols) > 0:
                    print(f"    æ•°å€¼åˆ—æ•°é‡: {len(numeric_cols)}")

            excel_count += 1

        except Exception as e:
            print(f"\\nâœ— {file['name']}: {e}")

if excel_count == 0:
    print("\\næœªæ‰¾åˆ° Excel æ–‡ä»¶")
else:
    print(f"\\næˆåŠŸå¤„ç† {excel_count} ä¸ª Excel æ–‡ä»¶")
""",

    "excel_sheet_merge": """import pandas as pd
import io
import base64

print("=" * 60)
print("Excel å¤š Sheet åˆå¹¶")
print("=" * 60)

for file in selected_files:
    if file['name'].endswith(('.xlsx', '.xls')):
        try:
            excel_bytes = base64.b64decode(file['content'])
            excel_file = pd.ExcelFile(io.BytesIO(excel_bytes))

            print(f"\\næ–‡ä»¶: {file['name']}")

            # è¯»å–æ‰€æœ‰ sheet å¹¶åˆå¹¶
            all_dfs = []
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(excel_file, sheet_name=sheet_name)
                df['source_sheet'] = sheet_name  # æ·»åŠ æ¥æºæ ‡è®°
                all_dfs.append(df)

            # åˆå¹¶
            merged_df = pd.concat(all_dfs, ignore_index=True)

            print(f"  åˆå¹¶å‰: {len(excel_file.sheet_names)} ä¸ª sheet")
            print(f"  åˆå¹¶å: {merged_df.shape}")
            print(f"\\nåˆå¹¶åçš„æ•°æ®é¢„è§ˆ:")
            print(merged_df.head(10))

            # æŒ‰æ¥æºåˆ†ç»„ç»Ÿè®¡
            print(f"\\næŒ‰æ¥æºåˆ†ç»„ç»Ÿè®¡:")
            print(merged_df.groupby('source_sheet').size())

        except Exception as e:
            print(f"âœ— {file['name']}: {e}")
"""
}
