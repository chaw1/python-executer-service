# Python Executor Service - é¡¹ç›®æ€»ç»“

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

**é¡¹ç›®åç§°**: Python Executor Service (Python ä»£ç æ‰§è¡Œå¾®æœåŠ¡)

**å®šä½**: ä¸ºæ™ºèƒ½æ•°æ®æ ‡æ³¨å¹³å°æä¾›å®‰å…¨çš„ Python ä»£ç æ‰§è¡Œèƒ½åŠ›ï¼Œä¸“æ³¨äº**æ•°æ®æ²»ç†**åŠŸèƒ½

**å½“å‰ç‰ˆæœ¬**: v1.2.0

**æŠ€æœ¯æ ˆ**:
- FastAPI (Web æ¡†æ¶)
- RestrictedPython (å®‰å…¨æ²™ç®±)
- Docker (å®¹å™¨åŒ–)
- NumPy, Pandas, Scikit-learn, Matplotlib, Plotly, Seaborn, SciPy (æ•°æ®ç§‘å­¦åº“)

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. æ•°æ®æ²»ç†æ ¸å¿ƒèƒ½åŠ›

#### 1.1 æ•°æ®é¢„å¤„ç†ä¸æ¸…æ´—
```python
# æ•°æ®æ¸…æ´—
df.drop_duplicates()
df.fillna(method='ffill')
df.replace(to_replace, value)

# æ•°æ®ç±»å‹è½¬æ¢
df['column'].astype('int')

# å¼‚å¸¸å€¼å¤„ç†
Q1 = df['column'].quantile(0.25)
Q3 = df['column'].quantile(0.75)
IQR = Q3 - Q1
```

#### 1.2 æ•°æ®æ ‡å‡†åŒ–ä¸å½’ä¸€åŒ–
```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Z-Score æ ‡å‡†åŒ–
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)

# Min-Max å½’ä¸€åŒ–
scaler_minmax = MinMaxScaler()
df_normalized = scaler_minmax.fit_transform(df)
```

#### 1.3 æ•°æ®ç»Ÿè®¡åˆ†æ
```python
# æè¿°æ€§ç»Ÿè®¡
df.describe()
df.info()
df.value_counts()

# ç›¸å…³æ€§åˆ†æ
df.corr()

# åˆ†ç»„èšåˆ
df.groupby('category').agg({'value': ['mean', 'sum', 'count']})
```

#### 1.4 æ•°æ®å¯è§†åŒ–
```python
# Matplotlib å›¾è¡¨
import matplotlib.pyplot as plt
plt.plot(x, y)
plt.hist(data)
plt.scatter(x, y)

# Seaborn é«˜çº§å¯è§†åŒ–
import seaborn as sns
sns.heatmap(df.corr(), annot=True)
sns.boxplot(x='category', y='value', data=df)

# Plotly äº¤äº’å¼å›¾è¡¨
import plotly.express as px
px.scatter(df, x='x', y='y', color='category')
```

### 2. æ•°æ®é›†ä¼ é€’åŠŸèƒ½ï¼ˆv1.2.0 æ–°å¢ï¼‰

**è§£å†³é—®é¢˜**: æ ‡æ³¨å¹³å°éœ€è¦å°†æ•°æ®ä¼ é€’ç»™ä»£ç æ‰§è¡ŒæœåŠ¡è¿›è¡Œæ²»ç†ï¼Œä½†å—å®‰å…¨é™åˆ¶æ— æ³•è®¿é—®æ–‡ä»¶ç³»ç»Ÿã€‚

**è§£å†³æ–¹æ¡ˆ**: é€šè¿‡ API ä¼ é€’æ•°æ®é›†å†…å®¹åˆ°æ‰§è¡Œç¯å¢ƒ

```python
# API è¯·æ±‚ç¤ºä¾‹
{
  "code": "import pandas as pd\ndf = pd.read_csv('data.csv')\nprint(df.describe())",
  "datasets": {
    "data.csv": "name,age,score\nAlice,25,95\nBob,30,87\nCharlie,22,92"
  }
}
```

**æ”¯æŒåœºæ™¯**:
- âœ… ç”¨æˆ·åœ¨æ ‡æ³¨å¹³å°ä¸Šä¼ æ•°æ®é›†
- âœ… å¹³å°å°†æ•°æ®å†…å®¹ä¼ é€’ç»™æ‰§è¡ŒæœåŠ¡
- âœ… ç”¨æˆ·ç¼–å†™æ•°æ®æ²»ç†ä»£ç ï¼ˆæ¸…æ´—ã€è½¬æ¢ã€åˆ†æï¼‰
- âœ… æœåŠ¡è¿”å›å¤„ç†ç»“æœå’Œå¯è§†åŒ–å›¾è¡¨
- âœ… å¹³å°å±•ç¤ºæ²»ç†åçš„æ•°æ®å’Œç»Ÿè®¡æŠ¥å‘Š

### 3. æœºå™¨å­¦ä¹ æ”¯æŒ

#### 3.1 æ•°æ®é¢„å¤„ç†
```python
from sklearn.preprocessing import (
    StandardScaler,      # æ ‡å‡†åŒ–
    MinMaxScaler,        # å½’ä¸€åŒ–
    LabelEncoder,        # æ ‡ç­¾ç¼–ç 
    OneHotEncoder        # ç‹¬çƒ­ç¼–ç 
)
```

#### 3.2 æ¨¡å‹è®­ç»ƒ
```python
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# è®­ç»ƒæ¨¡å‹
model = RandomForestClassifier()
model.fit(X_train, y_train)
predictions = model.predict(X_test)
```

#### 3.3 æ¨¡å‹è¯„ä¼°
```python
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix
)
```

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ ¸å¿ƒç»„ä»¶

```
æ™ºèƒ½æ•°æ®æ ‡æ³¨å¹³å°
    â†“
    â”‚ HTTP API
    â†“
Python Executor Service (FastAPI)
    â”‚
    â”œâ”€ API å±‚ (main.py)
    â”‚   â”œâ”€ POST /execute - æ‰§è¡Œä»£ç 
    â”‚   â”œâ”€ POST /validate - éªŒè¯ä»£ç 
    â”‚   â”œâ”€ GET /templates - è·å–æ¨¡æ¿
    â”‚   â””â”€ GET /health - å¥åº·æ£€æŸ¥
    â”‚
    â”œâ”€ æ‰§è¡Œå¼•æ“ (executor.py)
    â”‚   â”œâ”€ ä»£ç ç¼©è¿›æ ‡å‡†åŒ–
    â”‚   â”œâ”€ æ•°æ®é›†æ³¨å…¥
    â”‚   â”œâ”€ ä»£ç æ‰§è¡Œ
    â”‚   â”œâ”€ è¶…æ—¶æ§åˆ¶
    â”‚   â””â”€ ç»“æœæ•è·
    â”‚
    â”œâ”€ å®‰å…¨æ²™ç®± (sandbox.py)
    â”‚   â”œâ”€ RestrictedPython ç¼–è¯‘
    â”‚   â”œâ”€ æ¨¡å—ç™½åå•æ§åˆ¶
    â”‚   â”œâ”€ å±é™©æ“ä½œæ‹¦æˆª
    â”‚   â””â”€ ä»£ç éªŒè¯
    â”‚
    â””â”€ å¯è§†åŒ–æ•è· (visualizer.py)
        â”œâ”€ Matplotlib å›¾è¡¨æ•è·
        â”œâ”€ Plotly å›¾è¡¨æ•è·
        â””â”€ DataFrame è¡¨æ ¼æ•è·
```

### æ•°æ®æµç¨‹

```
1. æ ‡æ³¨å¹³å°å‘é€è¯·æ±‚
   â”œâ”€ code: Python ä»£ç ï¼ˆæ•°æ®æ²»ç†é€»è¾‘ï¼‰
   â”œâ”€ datasets: æ•°æ®æ–‡ä»¶å†…å®¹
   â””â”€ timeout: è¶…æ—¶æ—¶é—´

2. å®‰å…¨éªŒè¯
   â”œâ”€ ä»£ç è¯­æ³•æ£€æŸ¥
   â”œâ”€ å±é™©æ“ä½œæ£€æµ‹
   â””â”€ ç™½åå•éªŒè¯

3. æ‰§è¡Œå‡†å¤‡
   â”œâ”€ ä»£ç ç¼©è¿›æ ‡å‡†åŒ–
   â”œâ”€ æ•°æ®é›†æ³¨å…¥ï¼ˆè¦†ç›– pd.read_csvï¼‰
   â””â”€ æ²™ç®±ç¯å¢ƒåˆå§‹åŒ–

4. ä»£ç æ‰§è¡Œ
   â”œâ”€ ç¼–è¯‘ä»£ç ï¼ˆRestrictedPythonï¼‰
   â”œâ”€ æ‰§è¡Œä»£ç ï¼ˆç‹¬ç«‹ç¯å¢ƒï¼‰
   â””â”€ æ•è·è¾“å‡º

5. ç»“æœæ”¶é›†
   â”œâ”€ stdout/stderr è¾“å‡º
   â”œâ”€ å›¾è¡¨æ•è·ï¼ˆBase64 ç¼–ç ï¼‰
   â”œâ”€ DataFrame è¡¨æ ¼ï¼ˆHTMLï¼‰
   â””â”€ å˜é‡ä¿¡æ¯

6. è¿”å›å¹³å°
   â”œâ”€ status: success/error/timeout
   â”œâ”€ output: æ‰§è¡Œç»“æœ
   â”œâ”€ charts: å¯è§†åŒ–å›¾è¡¨
   â””â”€ dataframes: æ•°æ®è¡¨æ ¼
```

---

## ğŸ”’ å®‰å…¨æœºåˆ¶

### 1. RestrictedPython æ²™ç®±

**é™åˆ¶çš„æ“ä½œ**:
```python
# âŒ ç¦æ­¢çš„æ“ä½œ
open()          # æ–‡ä»¶è¯»å†™
eval()          # åŠ¨æ€ä»£ç æ‰§è¡Œ
exec()          # åŠ¨æ€ä»£ç æ‰§è¡Œ
import os       # æ“ä½œç³»ç»Ÿè®¿é—®
import sys      # ç³»ç»Ÿè®¿é—®
import subprocess  # è¿›ç¨‹æ‰§è¡Œ
__import__      # åŠ¨æ€å¯¼å…¥
```

**å…è®¸çš„åº“**:
```python
# âœ… æ•°æ®å¤„ç†
numpy, pandas, scipy

# âœ… æœºå™¨å­¦ä¹ 
scikit-learn

# âœ… å¯è§†åŒ–
matplotlib, plotly, seaborn
```

### 2. è¶…æ—¶æ§åˆ¶

- é»˜è®¤ 30 ç§’è¶…æ—¶
- å¯é…ç½® 1-60 ç§’
- é˜²æ­¢æ­»å¾ªç¯å’Œé•¿æ—¶é—´è¿è¡Œ

### 3. èµ„æºé™åˆ¶

```yaml
# Docker èµ„æºé™åˆ¶
deploy:
  resources:
    limits:
      cpus: '1.0'
      memory: 512M
```

### 4. ä»£ç éªŒè¯

```python
# æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å±é™©å…³é”®å­—
FORBIDDEN_PATTERNS = [
    r'\bopen\s*\(',
    r'\beval\s*\(',
    r'\bexec\s*\(',
    r'\b__import__\s*\(',
    # ... æ›´å¤š
]
```

---

## ğŸ“Š å¯¹æ¥åœºæ™¯

### åœºæ™¯ 1: æ•°æ®è´¨é‡æ£€æŸ¥

**å¹³å°ä¾§**:
```python
# ç”¨æˆ·ä¸Šä¼ æ•°æ®é›† data.csv
# å¹³å°è¯»å–å†…å®¹
csv_content = read_uploaded_file('data.csv')

# å‘é€åˆ°æ‰§è¡ŒæœåŠ¡
response = requests.post('http://executor:8000/execute', json={
    'code': user_code,  # ç”¨æˆ·ç¼–å†™çš„è´¨é‡æ£€æŸ¥ä»£ç 
    'datasets': {'data.csv': csv_content}
})

# å±•ç¤ºç»“æœ
show_results(response.json())
```

**ç”¨æˆ·ä»£ç **:
```python
import pandas as pd
import numpy as np

# è¯»å–æ•°æ®
df = pd.read_csv('data.csv')

# æ•°æ®è´¨é‡æ£€æŸ¥
print("=== æ•°æ®è´¨é‡æŠ¥å‘Š ===")
print(f"æ€»è¡Œæ•°: {len(df)}")
print(f"æ€»åˆ—æ•°: {len(df.columns)}")
print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:")
print(df.isnull().sum())
print(f"\né‡å¤è¡Œæ•°: {df.duplicated().sum()}")
print(f"\næ•°æ®ç±»å‹:")
print(df.dtypes)
```

### åœºæ™¯ 2: æ•°æ®æ¸…æ´—

**ç”¨æˆ·ä»£ç **:
```python
import pandas as pd
from sklearn.preprocessing import StandardScaler

# è¯»å–æ•°æ®
df = pd.read_csv('raw_data.csv')

# æ¸…æ´—æ­¥éª¤
# 1. åˆ é™¤é‡å¤
df = df.drop_duplicates()

# 2. å¡«å……ç¼ºå¤±å€¼
df['age'].fillna(df['age'].median(), inplace=True)

# 3. æ ‡å‡†åŒ–æ•°å€¼åˆ—
numeric_cols = df.select_dtypes(include=['number']).columns
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# 4. æ˜¾ç¤ºæ¸…æ´—åçš„æ•°æ®
print("æ¸…æ´—åçš„æ•°æ®:")
print(df.head())
print(f"\næ•°æ®å½¢çŠ¶: {df.shape}")

# è¿”å›æ¸…æ´—åçš„ DataFrameï¼ˆå¹³å°å¯ä»¥æ•è·ï¼‰
df
```

### åœºæ™¯ 3: æ•°æ®å¯è§†åŒ–åˆ†æ

**ç”¨æˆ·ä»£ç **:
```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# è¯»å–æ•°æ®
df = pd.read_csv('data.csv')

# 1. æ•°æ®åˆ†å¸ƒ
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.hist(df['age'], bins=20)
plt.title('å¹´é¾„åˆ†å¸ƒ')

plt.subplot(1, 3, 2)
plt.hist(df['score'], bins=20)
plt.title('åˆ†æ•°åˆ†å¸ƒ')

plt.subplot(1, 3, 3)
sns.boxplot(data=df[['age', 'score']])
plt.title('ç®±çº¿å›¾')

plt.tight_layout()
plt.show()

# 2. ç›¸å…³æ€§çƒ­åŠ›å›¾
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('ç‰¹å¾ç›¸å…³æ€§')
plt.show()
```

### åœºæ™¯ 4: æ•°æ®æ ‡æ³¨è¾…åŠ©

**ç”¨æˆ·ä»£ç **:
```python
import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# è¯»å–æœªæ ‡æ³¨æ•°æ®
df = pd.read_csv('unlabeled_data.csv')

# ä½¿ç”¨ K-Means èšç±»è¾…åŠ©æ ‡æ³¨
numeric_cols = df.select_dtypes(include=['number']).columns
X = df[numeric_cols]

# èšç±»
kmeans = KMeans(n_clusters=3, random_state=42)
df['cluster'] = kmeans.fit_predict(X)

# å¯è§†åŒ–èšç±»ç»“æœ
plt.figure(figsize=(10, 6))
plt.scatter(df[numeric_cols[0]], df[numeric_cols[1]],
            c=df['cluster'], cmap='viridis')
plt.xlabel(numeric_cols[0])
plt.ylabel(numeric_cols[1])
plt.title('èšç±»è¾…åŠ©æ ‡æ³¨')
plt.colorbar(label='Cluster')
plt.show()

# ç»Ÿè®¡æ¯ä¸ªèšç±»çš„ç‰¹å¾
print("èšç±»ç»Ÿè®¡:")
print(df.groupby('cluster')[numeric_cols].mean())

# è¿”å›å¸¦èšç±»æ ‡ç­¾çš„æ•°æ®
df
```

---

## ğŸ“ˆ æ ¸å¿ƒä¼˜åŠ¿

### 1. å®‰å…¨æ€§
- âœ… RestrictedPython æ²™ç®±éš”ç¦»
- âœ… ç™½åå•æœºåˆ¶ï¼Œåªå…è®¸å®‰å…¨çš„åº“
- âœ… Docker å®¹å™¨èµ„æºé™åˆ¶
- âœ… è¶…æ—¶æ§åˆ¶é˜²æ­¢æ¶æ„ä»£ç 

### 2. æ˜“ç”¨æ€§
- âœ… RESTful APIï¼Œç®€å•å¯¹æ¥
- âœ… æ™ºèƒ½ç¼©è¿›å¤„ç†ï¼Œå…¼å®¹å„ç§ä»£ç æ ¼å¼
- âœ… æ•°æ®é›†ä¼ é€’ï¼Œæ— éœ€æ–‡ä»¶ç³»ç»Ÿ
- âœ… å®Œæ•´çš„ Swagger API æ–‡æ¡£

### 3. åŠŸèƒ½æ€§
- âœ… å®Œæ•´çš„æ•°æ®ç§‘å­¦åº“æ”¯æŒ
- âœ… è‡ªåŠ¨æ•è·å›¾è¡¨å’Œè¡¨æ ¼
- âœ… æ”¯æŒæœºå™¨å­¦ä¹ å·¥ä½œæµ
- âœ… ä»£ç æ¨¡æ¿åº“

### 4. å¯æ‰©å±•æ€§
- âœ… Docker å®¹å™¨åŒ–ï¼Œæ˜“äºéƒ¨ç½²
- âœ… æ”¯æŒæ°´å¹³æ‰©å±•
- âœ… å¯é…ç½®èµ„æºé™åˆ¶
- âœ… æ—¥å¿—å®Œå–„ï¼Œæ˜“äºç›‘æ§

---

## ğŸ”§ æŠ€æœ¯å®ç°äº®ç‚¹

### 1. æ™ºèƒ½ä»£ç ç¼©è¿›æ ‡å‡†åŒ–

**é—®é¢˜**: ç”¨æˆ·ä»ç¼–è¾‘å™¨å¤åˆ¶çš„ä»£ç å¯èƒ½å¸¦æœ‰æ•´ä½“ç¼©è¿›

**è§£å†³**: `_normalize_code_indentation()` æ–¹æ³•
```python
def _normalize_code_indentation(self, code: str) -> str:
    """
    æ™ºèƒ½å¤„ç†ï¼š
    1. æ£€æµ‹å¹¶ç»Ÿä¸€åˆ¶è¡¨ç¬¦/ç©ºæ ¼
    2. æ‰¾åˆ°æœ€å°ç¼©è¿›ï¼ˆæ•´ä½“åç§»ï¼‰
    3. ç§»é™¤æ•´ä½“åç§»ï¼Œä¿ç•™ç›¸å¯¹ç¼©è¿›
    """
    # å®ç°ç»†èŠ‚è§ app/executor.py:41-116
```

### 2. æ•°æ®é›†æ³¨å…¥æœºåˆ¶

**é—®é¢˜**: å®‰å…¨æ²™ç®±ç¦æ­¢æ–‡ä»¶è®¿é—®ï¼Œä½†ç”¨æˆ·ä»£ç éœ€è¦è¯»å–æ•°æ®

**è§£å†³**: è¦†ç›– `pd.read_csv()` ç­‰å‡½æ•°
```python
def custom_read_csv(filepath_or_buffer, *args, **kwargs):
    if isinstance(filepath_or_buffer, str):
        # æ¸…ç† {{dataset_path}} å ä½ç¬¦
        clean_path = filepath_or_buffer.replace('{{dataset_path}}/', '')
        filename = os.path.basename(clean_path)

        # ä»å†…å­˜è¿”å›é¢„å¤„ç†çš„ DataFrame
        if filename in dataset_dataframes:
            return dataset_dataframes[filename].copy()

    return original_read_csv(filepath_or_buffer, *args, **kwargs)

# æ³¨å…¥åˆ°æ‰§è¡Œç¯å¢ƒ
global_vars['pd'].read_csv = custom_read_csv
```

### 3. å›¾è¡¨è‡ªåŠ¨æ•è·

**Matplotlib**:
```python
# æ•è·æ‰€æœ‰æ‰“å¼€çš„å›¾è¡¨
for i in plt.get_fignums():
    fig = plt.figure(i)
    buf = io.BytesIO()
    fig.savefig(buf, format='png')
    base64_img = base64.b64encode(buf.getvalue()).decode()
```

**Plotly**:
```python
# æ•è· Plotly å›¾è¡¨
if isinstance(var_value, (go.Figure, px._figure_py.Figure)):
    json_fig = var_value.to_json()
    charts.append({
        'type': 'plotly',
        'format': 'json',
        'data': json_fig
    })
```

### 4. Java DTO å…¼å®¹

**ä¼˜åŒ–**: ç®€åŒ– DataFrame è¾“å‡ºæ ¼å¼ï¼Œæ–¹ä¾¿ Java åç«¯è§£æ
```python
# Before (Python é£æ ¼)
{
  "shape": (5, 3),           # tuple
  "columns": ["A", "B", "C"] # list
}

# After (Java å‹å¥½)
{
  "rows": 5,                 # int
  "columns": 3               # int
}
```

---

## ğŸ“¦ éƒ¨ç½²æ–¹å¼

### å¼€å‘ç¯å¢ƒ
```bash
# æœ¬åœ°è¿è¡Œ
pip install -r requirements.txt
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### ç”Ÿäº§ç¯å¢ƒ
```bash
# Docker Compose
docker-compose up -d

# æˆ–å•ç‹¬æ„å»º
docker build -t python-executor-service:v1.2.0 .
docker run -d -p 8000:8000 \
  --cpus=1.0 --memory=512m \
  python-executor-service:v1.2.0
```

### å¯¹æ¥é…ç½®
```python
# æ ‡æ³¨å¹³å°é…ç½®
PYTHON_EXECUTOR_URL = "http://python-executor:8000"

# è°ƒç”¨ç¤ºä¾‹
import requests

def execute_data_governance(code, datasets):
    response = requests.post(
        f"{PYTHON_EXECUTOR_URL}/execute",
        json={
            "code": code,
            "datasets": datasets,
            "timeout": 30
        }
    )
    return response.json()
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### å“åº”æ—¶é—´
- **ç®€å•ä»£ç ** (print): < 50ms
- **æ•°æ®è¯»å–** (pd.read_csv): < 100ms
- **æ•°æ®å¤„ç†** (sklearn): < 500ms
- **å¤æ‚å›¾è¡¨**: < 1s

### å¹¶å‘èƒ½åŠ›
- **å•å®¹å™¨**: ~10 req/sï¼ˆCPU å¯†é›†å‹ä»»åŠ¡ï¼‰
- **æ‰©å±•**: æ”¯æŒæ°´å¹³æ‰©å±•ï¼ˆK8sï¼‰

### èµ„æºå ç”¨
- **å†…å­˜**: åŸºç¡€ ~150MBï¼Œæ‰§è¡Œæ—¶ < 512MB
- **CPU**: å•æ ¸ï¼ˆå¯é…ç½®ï¼‰

---

## ğŸ“š æ–‡æ¡£ä½“ç³»

### ç”¨æˆ·æ–‡æ¡£
- **README.md** - é¡¹ç›®æ€»è§ˆå’Œå¿«é€Ÿå¼€å§‹
- **QUICK_START.md** - å¿«é€Ÿå¼€å§‹æŒ‡å—
- **DATASETS_USAGE.md** - æ•°æ®é›†åŠŸèƒ½è¯¦ç»†ä½¿ç”¨æŒ‡å—
- **TEST_EXAMPLES.md** - æµ‹è¯•ç¤ºä¾‹å’Œä»£ç æ¨¡æ¿
- **æµ‹è¯•ä»£ç ç´¢å¼•.md** - ä¸­æ–‡æµ‹è¯•ä»£ç ç´¢å¼•

### æŠ€æœ¯æ–‡æ¡£
- **UPGRADE_SUMMARY.md** - å‡çº§æ€»ç»“
- **UPGRADE_TODO.md** - æœªæ¥è§„åˆ’
- **RELEASE_NOTES_v1.2.0.md** - ç‰ˆæœ¬å‘å¸ƒè¯´æ˜
- **DATASETS_FEATURE_SUMMARY.md** - æ•°æ®é›†åŠŸèƒ½å®ç°æ€»ç»“
- **API æ–‡æ¡£** - http://localhost:8000/docs (Swagger)

---

## ğŸ”® æœªæ¥è§„åˆ’

### v1.3.0 è®¡åˆ’åŠŸèƒ½

1. **ä¼šè¯ç®¡ç†** (P1)
   - å¤šæ­¥éª¤æ•°æ®å¤„ç†
   - å˜é‡æŒä¹…åŒ–
   - ä¸­é—´ç»“æœç¼“å­˜

2. **æ•°æ®å¯¼å‡º** (P1)
   - å¤„ç†åæ•°æ®å¯¼å‡ºä¸ºæ–‡ä»¶
   - æ”¯æŒå¤šç§æ ¼å¼ (CSV, JSON, Excel)

3. **Excel æ”¯æŒ** (P1)
   - `pd.read_excel()` æ”¯æŒ
   - `.xlsx` æ–‡ä»¶æ ¼å¼

4. **æ–‡ä»¶å¤§å°é™åˆ¶** (P2)
   - å¯é…ç½®çš„æ•°æ®é›†å¤§å°é™åˆ¶
   - åˆ†ç‰‡ä¸Šä¼ æ”¯æŒ

5. **ä»£ç è‡ªåŠ¨è¡¥å…¨** (P2)
   - API æä¾›ä»£ç è¡¥å…¨å»ºè®®
   - åŸºäºä¸Šä¸‹æ–‡çš„æ™ºèƒ½æç¤º

è¯¦è§ [UPGRADE_TODO.md](UPGRADE_TODO.md)

---

## ğŸ’¡ å…¸å‹ä½¿ç”¨åœºæ™¯æ€»ç»“

### 1. æ•°æ®è´¨é‡æ£€æŸ¥
ç”¨æˆ·ä¸Šä¼ æ•°æ® â†’ å¹³å°è°ƒç”¨æœåŠ¡æ‰§è¡Œè´¨é‡æ£€æŸ¥ä»£ç  â†’ è¿”å›è´¨é‡æŠ¥å‘Š

### 2. æ•°æ®æ¸…æ´—è½¬æ¢
ç”¨æˆ·ç¼–å†™æ¸…æ´—è§„åˆ™ â†’ æœåŠ¡æ‰§è¡Œæ¸…æ´— â†’ è¿”å›æ¸…æ´—åçš„æ•°æ®å’Œç»Ÿè®¡

### 3. æ•°æ®å¯è§†åŒ–
ç”¨æˆ·ç¼–å†™å¯è§†åŒ–ä»£ç  â†’ æœåŠ¡ç”Ÿæˆå›¾è¡¨ â†’ å¹³å°å±•ç¤ºå¯è§†åŒ–ç»“æœ

### 4. ç‰¹å¾å·¥ç¨‹
æ ‡æ³¨å‰çš„æ•°æ®é¢„å¤„ç† â†’ sklearn ç‰¹å¾æå–å’Œè½¬æ¢ â†’ è¿”å›å¤„ç†åçš„ç‰¹å¾

### 5. è¾…åŠ©æ ‡æ³¨
æœºå™¨å­¦ä¹ èšç±»/åˆ†ç±» â†’ ç”Ÿæˆæ ‡æ³¨å»ºè®® â†’ è¾…åŠ©äººå·¥æ ‡æ³¨

---

## ğŸ¯ é¡¹ç›®ä»·å€¼

ä¸ºæ™ºèƒ½æ•°æ®æ ‡æ³¨å¹³å°æä¾›ï¼š

1. **å®‰å…¨çš„ä»£ç æ‰§è¡Œç¯å¢ƒ** - ç”¨æˆ·å¯ä»¥è‡ªç”±ç¼–å†™æ•°æ®æ²»ç†é€»è¾‘
2. **å®Œæ•´çš„æ•°æ®ç§‘å­¦å·¥å…·é“¾** - æ”¯æŒä»æ¸…æ´—åˆ°åˆ†æçš„å…¨æµç¨‹
3. **çµæ´»çš„æ•°æ®ä¼ é€’æœºåˆ¶** - æ— ç¼å¯¹æ¥å¹³å°æ•°æ®
4. **ä¸°å¯Œçš„å¯è§†åŒ–èƒ½åŠ›** - è‡ªåŠ¨æ•è·å›¾è¡¨å’Œè¡¨æ ¼
5. **æ ‡å‡†çš„ REST API** - æ˜“äºé›†æˆå’Œæ‰©å±•

---

**ç‰ˆæœ¬**: v1.2.0
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
**æœ€åæ›´æ–°**: 2025-10-31
**ç»´æŠ¤å›¢é˜Ÿ**: Claude AI Assistant
